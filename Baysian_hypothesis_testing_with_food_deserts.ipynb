{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract: \n",
    "\n",
    "### Motivation:\n",
    "In recent years, many efforts have been made to address areas of low food access, and the detrimental health effects caused by \"Food Deserts\". \n",
    "\n",
    "Under healthcare reforms, providers are more accountable for patients following discharge. High levels of preventable readmissions result in penalties, and reduced federal reimbursement for services.\n",
    "\n",
    "### Goal:\n",
    "Explore factors that relate to 30 day readmissions.\n",
    "\n",
    "### Hypotheses:\n",
    "* Determine whether encounters that end with a patient leaving against medical advice have higher occurances of 30 day readmissions.\n",
    "* Determine whether encounters that end with a patient being discharged to skilled nuring facilities have higher occurances of 30 day readmissions.\n",
    "* Determine if patients admitted by Endocrinologists have lower 30 day readmission rates than those admitted by Internal Medicine physicians.\n",
    "\n",
    "### Conclusions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import linear_model\n",
    "from IPython.core.pylabtools import figsize\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/desert/desert_workspace/desert_data/clean_data.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df = df.fillna(0)\n",
    "df.rename(columns={'Influenza Death (<65 years of age)':'senior_flu_deaths'}, inplace=True)\n",
    "df.rename(columns={'Varicella Hospitalizations':'varicella_hospitalizations'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayes_df = df[['n_food_des','cnty_dm_pct_adj','LILATracts_1And10','POP2010' ]]\n",
    "bayes_df['group'] = bayes_df['LILATracts_1And10'] > np.mean(bayes_df['LILATracts_1And10'])\n",
    "bayes_df['group'].replace({False: 'low', True: 'high'},inplace=True)\n",
    "\n",
    "def make_percentage(val):\n",
    "    return val / 100\n",
    "\n",
    "bayes_df['cnty_dm_pct_adj'] = bayes_df['cnty_dm_pct_adj'].apply(make_percentage)\n",
    "\n",
    "bayes_df['n_diabetics']= bayes_df['cnty_dm_pct_adj'] * bayes_df['POP2010']\n",
    "bayes_df['n_diabetics']=bayes_df['n_diabetics'].astype(int)\n",
    "\n",
    "a = bayes_df[bayes_df['group']=='high']\n",
    "b = bayes_df[bayes_df['group']=='low']\n",
    "bayes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayes = bayes_df.groupby('group').agg(np.mean)\n",
    "bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis:\n",
    "## Do counties with a higher prevelance of Food Deserts have a higher prevelance of diabetes?\n",
    "\n",
    "### Method - AB testing using a Bayesian approach\n",
    "- A: Counties with a high prevelance of Food Deserts  \n",
    "    - Includes counties that have a higher prevelance of food deserts than the statewide average.\n",
    "\n",
    "- B: Counties with average to low prevelance of Food Deserts  \n",
    "    - Includes counties that have a food desert prevelance that is less than statewide average. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis focuses on finding the true frequency of diabetic residents based on observed frequencies of seen in counties with a high prevelance of food deserts, and a low-to-average prevelance of food deserts. The true frequency can be interpreted as the probability of an event occurring. For example, the true frequency of getting heads when flipping a fair coin is 1/2. \n",
    "\n",
    "Conversely, the observed frequency is what is actually observed. An example being if we flipped a coin 100 times we may observe 40 heads, and 60 tails. Therefore the observed frequency often differs from the true frequency. However, by applying a bayesian approach we can obtain a better sense of the true frequencies, allowing us to compare the likelihood of a CA county resident being diabetic between the different county groups specified above.\n",
    "\n",
    "To infer a probable value for the true frequency we can use the observed occurences in our dataset. Here we will compare the age adjusted diabetes prevelance between counties with a high prevelance of food deserts, and those with a low-to-average prevelance of food deserts. But first lets see how age adjusted diabetes rates vary among all CA counties, and each of these groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "figsize(12, 8)\n",
    "\n",
    "\n",
    "g=sns.distplot(bayes_df['cnty_dm_pct_adj'],\n",
    "            kde_kws={\"color\":\"b\",\"lw\":4,\"label\":\"KDE Estim - All CA counties\",\"alpha\":0.5},\n",
    "            hist_kws={\"color\":\"b\",\"alpha\":0.3,\"label\":\"All CA counties\"})\n",
    "\n",
    "sns.distplot(a['cnty_dm_pct_adj'],\n",
    "            kde_kws={\"color\":\"g\",\"lw\":4,\"label\":\"KDE Estim - high food des\",\"alpha\":0.5},\n",
    "            hist_kws={\"color\":\"g\",\"alpha\":0.3,\"label\":\"high food des\"})\n",
    "\n",
    "sns.distplot(b['cnty_dm_pct_adj'],\n",
    "            kde_kws={\"color\":\"r\",\"lw\":4,\"label\":\"KDE Estim - low-avg food des\",\"alpha\":0.5},\n",
    "            hist_kws={\"color\":\"r\",\"alpha\":0.3,\"label\":\"low-avg food des\"})\n",
    "\n",
    "# sns.distplot(bayes_df['cnty_dm_pct_adj']) # blue, statewide food desert prev\n",
    "# sns.distplot(a['cnty_dm_pct_adj']) # green, high food desert prev\n",
    "# sns.distplot(b['cnty_dm_pct_adj']) # red, avg to low food desert prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the distribution of county diabetes rates among all CA counties in blue. We can see that majority of counties fall somewhere between 6% and 9%. As stated above, this analysis will focus on comparing diabetes rates in counties with high and low-avg food desert prevelances, both of which fall within this window.\n",
    "\n",
    "First we assign our probabilities based on the observed diabetes rates amongst the different county groups. Then we assign the number of diabetic residents for each group based off the observations seen in our own dataset. After this we can generate new observations using what was observered in the data. Our generated samples are made using a Bernoulli distribution, meaning all values are 0 or 1.  \n",
    "\n",
    "0's represent county residents who do not have diabetes. 1's represent county residents who do have diabetes.\n",
    "\n",
    "All variables including A refer to high food desert counties and all variables including B refer to low to avg food desert counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def gen_obs(prob_col,n_col,frame):\n",
    "    # Probabilities based on the observed age adjusted diabetes rates amongst high(A) and low-to-avg(B) food_des_counties.\n",
    "    true_p_A = frame[prob_col].ix[0]\n",
    "    true_p_B = frame[prob_col].ix[1]\n",
    "    \n",
    "    # Sample size based on the observed number of county residents. Unequal sample sizes are acceptable in this type of Bayesian analysis.\n",
    "    N_A = np.round(frame[n_col].ix[0])\n",
    "    N_B = np.round(frame[n_col].ix[1])\n",
    "    \n",
    "    # Generates new observations based on what was observered in the data using a Bernoulli distribution.\n",
    "    observations_A = pm.rbernoulli(true_p_A, N_A)\n",
    "    observations_B = pm.rbernoulli(true_p_B, N_B)\n",
    "    print \"Diabetic county residents - group A (High food desert prevelance): \\n\", observations_A[:30].astype(int), \"...\"\n",
    "    print \"Diabetic county residents - group B (Low to average food desert prevelance): \\n\", observations_B[:30].astype(int), \"...\"\n",
    "    return true_p_A, true_p_B, N_A, N_B, observations_A, observations_B\n",
    "    \n",
    "true_p_A, true_p_B, N_A, N_B, observations_A, observations_B = gen_obs('cnty_dm_pct_adj','POP2010',bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print observations_A.mean() \n",
    "print observations_B.mean()\n",
    "\n",
    "# Occurrences.mean is equal to n/N.\n",
    "print \"Observed frequency of diabetic residents in High food desert counties: %.4f\" % observations_A.mean()\n",
    "print \"Does this observed frequency (%f) equal the true frequency (%f) in original dataset? %s\" % (observations_A.mean(), true_p_A, observations_A.mean() == true_p_A)\n",
    "\n",
    "print\n",
    "print \"Observed frequency of diabetic residents in Low-to-Average food desert counties: %.4f\" % observations_B.mean()\n",
    "print \"Does this observed frequency (%f) equal the true frequency (%f) in original dataset? %s\" % (observations_B.mean(), true_p_B, observations_B.mean() == true_p_B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we assign our priors to a Uniform distibution. This is a conservative approach, which should be utilized when you do not possess a firm belief about the prior distribution. Then we must define the deterministic delta function. Delta, the return value from this function, represents our estimates of the true frequencies. Finally, we generate observations for our model and use a Markov Chain Monte Carlo model to return samples from the posterior distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the pymc model. Again assume Uniform priors for p_A and p_B. \n",
    "p_A = pm.Uniform(\"p_A\", 0, 1)\n",
    "p_B = pm.Uniform(\"p_B\", 0, 1)\n",
    "\n",
    "# Define the deterministic delta function. This is our unknown of interest. \n",
    "@pm.deterministic\n",
    "def delta(p_A=p_A, p_B=p_B):\n",
    "    return p_A - p_B\n",
    "\n",
    "# Set of observations, in this case we have two observation datasets. \n",
    "obs_A = pm.Bernoulli(\"obs_A\", p_A, value=observations_A, observed=True) \n",
    "obs_B = pm.Bernoulli(\"obs_B\", p_B, value=observations_B, observed=True)\n",
    "\n",
    "mcmc = pm.MCMC([p_A, p_B, delta, obs_A, obs_B]) \n",
    "mcmc.sample(20000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below assigns our posterior samples according to class and our delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_A_samples = mcmc.trace(\"p_A\")[:] \n",
    "p_B_samples = mcmc.trace(\"p_B\")[:] \n",
    "delta_samples = mcmc.trace(\"delta\")[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_AB(p_A_samples, true_p_A, p_B_samples, true_p_B, delta_samples):\n",
    "    figsize(12.5, 10)\n",
    "    ax = plt.subplot(311)\n",
    "    plt.xlim(0.05, .08)\n",
    "    plt.hist(p_A_samples, histtype='stepfilled', bins=25, alpha=0.85,\n",
    "             label=\"posterior of $p_A$\", color=\"#A60628\", normed=True)\n",
    "    plt.vlines(true_p_A, 0, 700, linestyle=\"--\", label=\"true $p_A$ (unknown)\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(\"Posterior distributions of $p_A(High:desert)$, $p_B(LowAvg:desert)$, and delta unknowns\")\n",
    "    \n",
    "    ax = plt.subplot(312)\n",
    "    plt.xlim(0.05, .08)\n",
    "    plt.hist(p_B_samples, histtype='stepfilled', bins=25, alpha=0.85,\n",
    "             label=\"posterior of $p_B$\", color=\"#467821\", normed=True)\n",
    "    plt.vlines(true_p_B, 0, 1400, linestyle=\"--\", label=\"true $p_B$ (unknown)\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    \n",
    "    ax = plt.subplot(313)\n",
    "    plt.xlim(-0.001, .006)\n",
    "    plt.hist(delta_samples, histtype='stepfilled', bins=30, alpha=0.85,\n",
    "             label=\"posterior of delta\", color=\"#7A68A6\", normed=True)\n",
    "    plt.vlines(true_p_A - true_p_B, 0, 800, linestyle=\"--\",label=\"true delta (unknown)\")\n",
    "    plt.vlines(0, 0, 800, color=\"black\", alpha=0.2)\n",
    "    plt.legend(loc=\"upper right\");\n",
    "\n",
    "plot_AB(p_A_samples, true_p_A, p_B_samples, true_p_B, delta_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there is have less high food desert counties, our posterior distribution of pA is fatter, implying we are less certain about the true value of pA than we are of pB.\n",
    "We can see that the majority of the posterior distribution of delta is above delta=0, implying that high food desert county residents are more likely to be diabetic than residents living in a low to average food desert county. The probability that this inference is incorrect is computed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count the number of samples less than 0, i.e. the area under the curve\n",
    "# before 0, represents the probability that A residents are \n",
    "# less likely to be diabetic than B residents.\n",
    "print \"Probability high food desert counties have LESS diabetic residents than low food desert counties: %.3f\" % \\\n",
    "(delta_samples < 0).mean()\n",
    "\n",
    "print \"Probability high food desert counties have More diabetic residents than low food desert counties: %.3f\" % \\\n",
    "(delta_samples > 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we can state the probability of a California resident being diabetic is significantly less if they live in a county that has a low to average prevelance of food deserts. Similarly, we can also state those living in CA counties with a high prevelance of food deserts are significantly more likely to be diabetic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "Infection Rates: The rate of disease per 100,000 population for the corresponding County, Year, Sex strata using the standard calculation (Count *100,000/Population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayes_df=df[['n_urban','n_rural','County','unemployment_rate','pop2010_in_des','SODA_PRICE10','n_food_des','PC_PHYS_R','FFR07','LILATracts_1And10','POP2010', 'Chlamydia','Tuberculosis','Gonorrhea','HIV','senior_flu_deaths','Measles','Mumps','Pertussis','Rubella','varicella_hospitalizations']]\n",
    "bayes_df['group'] = bayes_df['LILATracts_1And10'] > np.mean(bayes_df['LILATracts_1And10'])\n",
    "bayes_df['group'].replace({False: 'low', True: 'high'},inplace=True)\n",
    "\n",
    "\n",
    "def infx_counts(infx_rate, population):\n",
    "    count= (infx_rate /100000) * population \n",
    "    return np.int64(count)\n",
    "\n",
    "def append_infx_counts(disease_lst, new_names):\n",
    "    new_frame = bayes_df.copy(deep=False)\n",
    "    print new_frame.columns\n",
    "    for col, new_col in zip(disease_lst,new_names):\n",
    "        new_frame[new_col] = infx_counts(bayes_df[col],bayes_df['POP2010'])\n",
    "    return new_frame.drop(disease_lst,axis=1)\n",
    "\n",
    "preventable_dx = ['Chlamydia','Tuberculosis','Gonorrhea','HIV','senior_flu_deaths','Measles','Mumps','Pertussis','Rubella','varicella_hospitalizations']\n",
    "new_feat_names = [col+'_count' for col in preventable_dx]\n",
    "\n",
    "bayes_df = append_infx_counts(preventable_dx, new_feat_names)\n",
    "\n",
    "bayes_df[\"std_incidence\"] = bayes_df[['Chlamydia_count','Gonorrhea_count','HIV_count']].sum(axis=1)\n",
    "bayes_df[\"vaccine_related_incidences\"] = bayes_df[['Tuberculosis_count','senior_flu_deaths_count','Measles_count','Mumps_count','Pertussis_count','Rubella_count','varicella_hospitalizations_count']].sum(axis=1)\n",
    "bayes_df = bayes_df[[col for col in bayes_df.columns if col not in new_feat_names]]\n",
    "bayes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=bayes_df[bayes_df['group']=='high']['SODA_PRICE10']\n",
    "b=bayes_df[bayes_df['group']=='low']['SODA_PRICE10']\n",
    "y = pd.DataFrame(dict(value=np.r_[a, b], group=np.r_[['high']*len(a), ['low']*len(b)]))\n",
    "\n",
    "y.hist('value', by='group');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu_m = y.value.mean()\n",
    "mu_s = y.value.std() * 2\n",
    "\n",
    "with pm.Model() as model:\n",
    "\n",
    "    group1_mean = pm.Normal('group1_mean', mu_m, sd=mu_s)\n",
    "    group2_mean = pm.Normal('group2_mean', mu_m, sd=mu_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_low = 1\n",
    "theta_high = 10\n",
    "\n",
    "with model:\n",
    "\n",
    "    group1_std = pm.Uniform('group1_std', lower=theta_low, upper=theta_high)\n",
    "    group2_std = pm.Uniform('group2_std', lower=theta_low, upper=theta_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "\n",
    "    v = pm.Exponential('v_minus_one', 1/29.) + 1\n",
    "\n",
    "sns.distplot(np.random.exponential(30, size=10000), kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "\n",
    "    lambda1 = group1_std**-2\n",
    "    lambda2 = group2_std**-2\n",
    "\n",
    "    group1 = pm.StudentT('drug', nu=v, mu=group1_mean, lam=lambda1, observed=a)\n",
    "    group2 = pm.StudentT('placebo', nu=v, mu=group2_mean, lam=lambda2, observed=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "\n",
    "    diff_of_means = pm.Deterministic('difference of means', group1_mean - group2_mean)\n",
    "    diff_of_stds = pm.Deterministic('difference of stds', group1_std - group2_std)\n",
    "    effect_size = pm.Deterministic('effect size', diff_of_means / pm.sqrt((group1_std**2 + group2_std**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(2000, njobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you want to create a video and embed that run this cell instead.\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "VIDEO_TAG = \"\"\"<video controls>\n",
    " <source src=\"data:video/x-m4v;base64,{0}\" type=\"video/mp4\">\n",
    " Your browser does not support the video tag.\n",
    "</video>\"\"\"\n",
    "\n",
    "def anim_to_html(anim):\n",
    "    if not hasattr(anim, '_encoded_video'):\n",
    "        with NamedTemporaryFile(suffix='.mp4') as f:\n",
    "            anim.save(f.name, fps=20, extra_args=['-vcodec', 'libx264', '-pix_fmt', 'yuv420p'])\n",
    "            video = open(f.name, \"rb\").read()\n",
    "        with NamedTemporaryFile(suffix='.avi') as f:\n",
    "            anim.save(f.name, fps=20, extra_args=['-vcodec', 'libx264', '-pix_fmt', 'yuv420p'])\n",
    "            video = open(f.name, \"rb\").read()\n",
    "        anim._encoded_video = video.encode(\"base64\")\n",
    "    \n",
    "    return VIDEO_TAG.format(anim._encoded_video)\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "\n",
    "def display_animation(anim):\n",
    "    plt.close(anim._fig)\n",
    "    return HTML(anim_to_html(anim))\n",
    "\n",
    "animation.Animation._repr_html_ = anim_to_html\n",
    "\n",
    "# Generate some data\n",
    "np.random.seed(124)\n",
    "size = 50\n",
    "true_intercept = 1\n",
    "true_slope = 2\n",
    "\n",
    "x = np.linspace(0, 1, size)\n",
    "y = true_intercept + x*true_slope + np.random.normal(scale=.5, size=size)\n",
    "\n",
    "data = dict(x=x, y=y)\n",
    "\n",
    "# Quickly hacked plotting code\n",
    "samples = 600\n",
    "figsize(6, 6)\n",
    "fig = plt.figure()\n",
    "i_width = (true_intercept-.7, true_intercept+.7)\n",
    "s_width = (true_slope-.7, true_slope+.7)\n",
    "samples_width = (0, samples)\n",
    "ax1 = fig.add_subplot(221, xlim=i_width, ylim=samples_width)\n",
    "ax2 = fig.add_subplot(224, xlim=samples_width, ylim=s_width)\n",
    "ax3 = fig.add_subplot(223, xlim=i_width, ylim=s_width,\n",
    "                      xlabel='intercept',\n",
    "                      ylabel='slope')\n",
    "fig.subplots_adjust(wspace=0.0, hspace=0.0)\n",
    "line1, = ax1.plot([], [], lw=1)\n",
    "line2, = ax2.plot([], [], lw=1)\n",
    "line3, = ax3.plot([], [], 'o', lw=2, alpha=.1)\n",
    "line4, = ax3.plot([], [], lw=1, alpha=.3)\n",
    "line5, = ax3.plot([], [], 'k', lw=1)\n",
    "line6, = ax3.plot([], [], 'k', lw=1)\n",
    "ax1.set_xticklabels([])\n",
    "ax2.set_yticklabels([])\n",
    "#path = plt.scatter([], [])\n",
    "lines = [line1, line2, line3, line4, line5, line6]\n",
    "\n",
    "def init():\n",
    "    for line in lines:\n",
    "        line.set_data([], [])\n",
    "    return lines\n",
    "\n",
    "def animate(i):\n",
    "    with model:\n",
    "        if i == samples * .75:\n",
    "            for j in range(500): iter_sample.next() \n",
    "        trace = iter_sample.next()\n",
    "    line1.set_data(trace['Intercept'][::-1], range(len(trace['Intercept'])))\n",
    "    line2.set_data(range(len(trace['x'])), trace['x'][::-1])\n",
    "    line3.set_data(trace['Intercept'], trace['x'])\n",
    "    line4.set_data(trace['Intercept'], trace['x'])\n",
    "    intercept = trace['Intercept'][-1]\n",
    "    x = trace['x'][-1]\n",
    "    line5.set_data([intercept, intercept], [x, s_width[1]])\n",
    "    line6.set_data([intercept, i_width[1]], [x, x])\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No MovieWriters available!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/Users/desert/anaconda/envs/linreg/lib/python2.7/site-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_get_formatter_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/desert/anaconda/envs/linreg/lib/python2.7/site-packages/matplotlib/animation.pyc\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0mfmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'animation.html'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'html5'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html5_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/desert/anaconda/envs/linreg/lib/python2.7/site-packages/matplotlib/animation.pyc\u001b[0m in \u001b[0;36mto_html5_video\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    949\u001b[0m                 \u001b[0;31m# We create a writer manually so that we can get the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                 \u001b[0;31m# appropriate size for the tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                 \u001b[0mWriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwriters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'animation.writer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 writer = Writer(codec='h264',\n\u001b[1;32m    953\u001b[0m                                 \u001b[0mbitrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'animation.bitrate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/desert/anaconda/envs/linreg/lib/python2.7/site-packages/matplotlib/animation.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No MovieWriters available!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No MovieWriters available!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.animation.FuncAnimation at 0x10d13ad10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109f9d650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with pm.Model() as model:\n",
    "#     pm.glm.glm('y ~ x', data)\n",
    "#     step = pm.Metropolis()\n",
    "#     iter_sample = pm.iter_sample(samples+1000, step)\n",
    "\n",
    "# animation.FuncAnimation(fig, animate, init_func=init,\n",
    "#                         frames=samples, interval=5, blit=True)\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlim(( 0, 2))\n",
    "ax.set_ylim((-2, 2))\n",
    "\n",
    "line, = ax.plot([], [], lw=2)\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return (line,)\n",
    "\n",
    "# animation function. This is called sequentially\n",
    "def animate(i):\n",
    "    x = np.linspace(0, 2, 1000)\n",
    "    y = np.sin(2 * np.pi * (x - 0.01 * i))\n",
    "    line.set_data(x, y)\n",
    "    return (line,)\n",
    "\n",
    "# call the animator. blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=100, interval=20, blit=True)\n",
    "\n",
    "#HTML(anim.to_html5_video())\n",
    "rc('animation', html='html5')\n",
    "anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "    pm.glm.glm('y ~ x', data)\n",
    "    step = pm.Slice()\n",
    "    iter_sample = pm.iter_sample(samples+1000, step)\n",
    "\n",
    "animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                        frames=samples, interval=5, blit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pm.forestplot(trace[1000:], varnames=[v.name for v in model.vars])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(pm.diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm.plot_posterior(trace[1000:],\n",
    "                  varnames=['difference of means', 'difference of stds', 'effect size'],\n",
    "                  ref_val=0,\n",
    "                  color='#87ceeb');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prev_dx_ratio(frame, val_feat, pop_val):\n",
    "    return frame[val_feat] / frame[pop_val]\n",
    "\n",
    "\n",
    "bayes = bayes_df.groupby('group').agg(np.sum)\n",
    "bayes['std_rate'] = bayes['std_incidence'] / bayes['POP2010']\n",
    "bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sns.jointplot(y='n_food_des', x='std_incidence', data=bayes_df, kind='reg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import seaborn.apionly as sns\n",
    "import statsmodels.api as sm\n",
    "import theano.tensor as tt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')\n",
    "colors = ['#348ABD', '#A60628', '#7A68A6', '#467821', '#D55E00', \n",
    "          '#CC79A7', '#56B4E9', '#009E73', '#F0E442', '#0072B2']\n",
    "\n",
    "def make_percentage(val):\n",
    "    return val / 100\n",
    "\n",
    "bayes_df['unemployment_rate'] = bayes_df['unemployment_rate'].apply(make_percentage)\n",
    "\n",
    "bayes_df['n_unemployed']= bayes_df['unemployment_rate'] * bayes_df['POP2010']\n",
    "bayes_df['n_unemployed']=bayes_df['n_unemployed'].astype(int)\n",
    "bayes_df.head()\n",
    "#df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X = bayes_df[['n_urban','n_rural','n_unemployed','std_incidence']].values\n",
    "_, num_X = X.shape\n",
    "\n",
    "with pm.Model() as model:       \n",
    "    intercept = pm.Normal('intercept', mu=0, sd=100)\n",
    "    beta_n_urban = pm.Normal('beta_n_urban', mu=0, sd=100)\n",
    "    beta_std_incidence = pm.Normal('beta_std_incidence', mu=0, sd=100)\n",
    "    beta_n_unemployed = pm.Normal('beta_n_unemployed', mu=0, sd=100)\n",
    "    \n",
    "    mu = tt.exp(intercept \n",
    "                + beta_n_urban*bayes_df.n_urban \n",
    "                + beta_std_incidence*bayes_df.std_incidence\n",
    "                + beta_n_unemployed*bayes_df.n_unemployed)\n",
    "    \n",
    "    y_est = pm.Poisson('y_est', mu=mu, observed=bayes_df['n_food_des'].values)\n",
    "    \n",
    "    start = pm.find_MAP()\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(200000, step, start=start, progressbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = pm.traceplot(trace)\n",
    "#The main takeaway from this is that the effect of changing x \n",
    "#depends on the current value of y. Unlike the simple linear regression, \n",
    "# a unit change in x does not cause a consistent change in y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = sns.pairplot(pm.trace_to_dataframe(trace[20000:]), plot_kws={'alpha':.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = bayes_df['n_unemployed'].plot(\n",
    "    kind='bar', figsize=(12,3), title='Number of unemployed per county', color=colors[0])\n",
    "_ = ax.set_xlabel(bayes_df['County'])\n",
    "_ = ax.set_ylabel('Number of fds')\n",
    "_ = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indiv_traces = {}\n",
    "\n",
    "\n",
    "n_counties = len(bayes_df['County'])\n",
    "\n",
    "for p in bayes_df['County']:\n",
    "    with pm.Model() as model:\n",
    "        alpha = pm.Uniform('alpha', lower=0, upper=100)\n",
    "        mu = pm.Uniform('mu', lower=0, upper=100)\n",
    "        \n",
    "        data = bayes_df[messages['prev_sender']==p]['time_delay_seconds'].values\n",
    "        y_est = pm.NegativeBinomial('y_est', mu=mu, alpha=alpha, observed=data)\n",
    "\n",
    "        y_pred = pm.NegativeBinomial('y_pred', mu=mu, alpha=alpha)\n",
    "        \n",
    "        start = pm.find_MAP()\n",
    "        step = pm.Metropolis()\n",
    "        trace = pm.sample(20000, step, start=start, progressbar=True)\n",
    "        \n",
    "        indiv_traces[p] = trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymc3 import  *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "size = 200\n",
    "true_intercept = 1\n",
    "true_slope = 2\n",
    "\n",
    "x = np.linspace(0, 1, size)\n",
    "# y = a + b*x\n",
    "true_regression_line = true_intercept + true_slope * x\n",
    "# add noise\n",
    "y = true_regression_line + np.random.normal(scale=.5, size=size)\n",
    "\n",
    "data = dict(x=x, y=y)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, xlabel='x', ylabel='y', title='Generated data and underlying model')\n",
    "ax.scatter(x, y, label='sampled data')\n",
    "ax.plot(x, true_regression_line, label='true regression line', lw=2., color='r')\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with Model() as model: # model specifications in PyMC3 are wrapped in a with-statement\n",
    "    # Define priors\n",
    "    sigma = HalfCauchy('sigma', beta=10, testval=1.)\n",
    "    intercept = Normal('Intercept', 0, sd=20)\n",
    "    x_coeff = Normal('x', 0, sd=20)\n",
    "\n",
    "    # Define likelihood\n",
    "    likelihood = Normal('y', mu=intercept + x_coeff * x,\n",
    "                        sd=sigma, observed=y)\n",
    "\n",
    "    # Inference!\n",
    "    start = find_MAP() # Find starting value by optimization\n",
    "    step = NUTS(scaling=start) # Instantiate MCMC sampling algorithm\n",
    "    trace = sample(2000, step, start=start, progressbar=False) # draw 2000 posterior samples using NUTS sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "traceplot(trace[100:])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(x, y, label='data')\n",
    "glm.plot_posterior_predictive(trace, samples=100,\n",
    "                              label='posterior predictive regression lines')\n",
    "plt.plot(x, true_regression_line, label='true regression line', lw=3., c='y')\n",
    "\n",
    "plt.title('Posterior predictive regression lines')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with Model() as model:\n",
    "    # specify glm and pass in data. The resulting linear model, its likelihood and\n",
    "    # and all its parameters are automatically added to our model.\n",
    "    glm.glm('y ~ x', data)\n",
    "    start = find_MAP()\n",
    "    step = NUTS(scaling=start) # Instantiate MCMC sampling algorithm\n",
    "    trace = sample(2000, step, progressbar=False) # draw 2000 posterior samples using NUTS sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N=len(bayes_df)\n",
    "X = df['std_incidence'].values\n",
    "Y = df['LILATracts_1And10'].values\n",
    "\n",
    "ls_coef_ = np.cov(X, Y)[0, 1] / np.var(X)\n",
    "ls_intercept = Y.mean() - ls_coef_ * X.mean()\n",
    "\n",
    "plt.scatter(X, Y, c=\"k\")\n",
    "plt.xlabel(\"% County Tracts Food deserts\")\n",
    "plt.ylabel(\"PCP Civilian ratio\")\n",
    "plt.title(\"Food deserts Prevelance vs MD ratios\")\n",
    "plt.plot(X, ls_coef_ * X + ls_intercept, label=\"Least-squares line\")\n",
    "plt.xlim(X.min(), X.max())\n",
    "plt.ylim(Y.min(), Y.max())\n",
    "plt.legend(loc=\"lower right\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano\n",
    "\n",
    "with pm.Model() as model:\n",
    "    pm.glm.glm('LILATracts_1And10 ~ PCT_WHITE', df)\n",
    "    start = pm.find_MAP()\n",
    "    step = pm.NUTS(scaling=start)\n",
    "    trace = pm.sample(2000, step, progressbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(111, xlabel='x', ylabel='y', \n",
    "            title='Posterior predictive regression lines')\n",
    "#plt.plot(x_out, y_out, 'x', label='data')\n",
    "pm.glm.plot_posterior_predictive(trace, samples=100, \n",
    "                                 label='posterior predictive regression lines')\n",
    "# plt.plot(x, true_regression_line, \n",
    "#          label='true regression line', lw=3., c='y')\n",
    "plt.plot(X, ls_coef_ * X + ls_intercept, label=\"Least-squares line\")\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymc.Matplot import plot as mcplot\n",
    "\n",
    "std = pm.Uniform(\"std\", 0, 100, trace=False)  # this needs to be explained.\n",
    "\n",
    "\n",
    "@pm.deterministic\n",
    "def prec(U=std):\n",
    "    return 1.0 / (U) ** 2\n",
    "\n",
    "beta = pm.Normal(\"beta\", 0, 0.0001)\n",
    "alpha = pm.Normal(\"alpha\", 0, 0.0001)\n",
    "\n",
    "\n",
    "@pm.deterministic\n",
    "def mean(X=X, alpha=alpha, beta=beta):\n",
    "    return alpha + beta * X\n",
    "\n",
    "obs = pm.Normal(\"obs\", mean, prec, value=Y, observed=True)\n",
    "mcmc = pm.MCMC([obs, beta, alpha, std, prec])\n",
    "\n",
    "mcmc.sample(100000, 80000)#plot alpha,beta,& prec after sampling 100000 more times, burning 80000 samples, and return every 5th sample (thining).\n",
    "mcplot(mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figsize(12.5, 6)\n",
    "from scipy.optimize import fmin\n",
    "\n",
    "\n",
    "def abr_prev(des, pred, coef=500):\n",
    "    \"\"\"vectorized for numpy\"\"\"\n",
    "    sol = np.zeros_like(des)\n",
    "    ix = des * pred < 0\n",
    "    sol[ix] = coef * pred ** 2 - np.sign(des[ix]) * pred + abs(des[ix])\n",
    "    sol[~ix] = abs(des[~ix] - pred)\n",
    "    return sol\n",
    "\n",
    "tau_samples = mcmc.trace(\"prec\")[:]\n",
    "alpha_samples = mcmc.trace(\"alpha\")[:]\n",
    "beta_samples = mcmc.trace(\"beta\")[:]\n",
    "\n",
    "N = tau_samples.shape[0]\n",
    "\n",
    "noise = 1. / np.sqrt(tau_samples) * np.random.randn(N)\n",
    "\n",
    "possible_outcomes = lambda signal: alpha_samples + beta_samples * signal \\\n",
    "    + noise\n",
    "\n",
    "\n",
    "opt_predictions = np.zeros(50)\n",
    "num_deserts = np.linspace(X.min(), X.max(), 50)\n",
    "for i, _des in enumerate(num_deserts):\n",
    "    _possible_outcomes = possible_outcomes(_des)\n",
    "    tomin = lambda pred: abr_prev(_possible_outcomes, pred).mean()\n",
    "    opt_predictions[i] = fmin(tomin, 0, disp=False)\n",
    "\n",
    "plt.scatter(X, Y, c=\"k\")\n",
    "plt.xlabel(\"County Food Deserts Prevelance\")\n",
    "plt.ylabel(\"ABR prediction\")\n",
    "plt.title(\"Least-squares prediction vs. Bayes action prediction\")\n",
    "plt.plot(X, ls_coef_ * X + ls_intercept, label=\"Least-squares prediction\")\n",
    "plt.xlim(X.min(), X.max())\n",
    "plt.plot(num_deserts, opt_predictions, label=\"Bayes action prediction\")\n",
    "plt.legend(loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=bayes[['std_incidence','POP2010']].ix[0].values\n",
    "b=bayes[['std_incidence','POP2010']].ix[1].values\n",
    "# data_A = np.r_[[0] * (a[0] - a[1]), [1] * a[1]]\n",
    "# data_B = np.r_[[0] * (b[0] - b[1]), [1] * b[1]]\n",
    "\n",
    "def gen_obs(prob_col,n_col,frame):\n",
    "    # Probabilities based on the observed age adjusted diabetes rates amongst high(A) and low-to-avg(B) food_des_counties.\n",
    "    true_p_A = frame[prob_col].ix[0]\n",
    "    true_p_B = frame[prob_col].ix[1]\n",
    "    \n",
    "    # Sample size based on the observed number of county residents. Unequal sample sizes are acceptable in this type of Bayesian analysis.\n",
    "    N_A = np.round(frame[n_col].ix[0])\n",
    "    N_B = np.round(frame[n_col].ix[1])\n",
    "    \n",
    "    # Generates new observations based on what was observered in the data using a Bernoulli distribution.\n",
    "    observations_A = pm.rbernoulli(true_p_A, N_A)\n",
    "    observations_B = pm.rbernoulli(true_p_B, N_B)\n",
    "    print \"Diabetic county residents - group A (High food desert prevelance): \\n\", observations_A[:30].astype(int), \"...\"\n",
    "    print \"Diabetic county residents - group B (Low to average food desert prevelance): \\n\", observations_B[:30].astype(int), \"...\"\n",
    "    return true_p_A, true_p_B, N_A, N_B, observations_A, observations_B\n",
    "    \n",
    "true_p_A, true_p_B, N_A, N_B, observations_A, observations_B = gen_obs('std_rate','POP2010',bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_rates = np.random.beta(51, 51, size=1000)\n",
    "true_rates\n",
    "obs = np.random.binomial(100, true_rates)\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clicks_A = 1135\n",
    "orders_A = 5\n",
    "clicks_B = 1149\n",
    "orders_B = 17\n",
    "data_A = np.r_[[0] * (clicks_A - orders_A), [1] * orders_A]\n",
    "data_B = np.r_[[0] * (clicks_B - orders_B), [1] * orders_B]\n",
    "data_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "figsize(12, 4)\n",
    "\n",
    "def gen_obs(prob_col,n_col,frame):\n",
    "    true_p_A = frame[prob_col].ix[0]\n",
    "    true_p_B = frame[prob_col].ix[1]\n",
    "    N_A = np.round(frame[n_col].ix[0])\n",
    "    N_B = np.round(frame[n_col].ix[1])\n",
    "    observations_A = pm.rbernoulli(true_p_A, N_A)\n",
    "    observations_B = pm.rbernoulli(true_p_B, N_B)\n",
    "    print \"Obs from Site A: \", observations_A[:30].astype(int), \"...\"\n",
    "    print \"Obs from Site B: \", observations_B[:30].astype(int), \"...\"\n",
    "    return true_p_A, true_p_B, N_A, N_B, observations_A, observations_B\n",
    "    \n",
    "true_p_A, true_p_B, N_A, N_B, observations_A, observations_B = gen_obs('cnty_dm_pct','POP2010',bayes)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [linreg]",
   "language": "python",
   "name": "Python [linreg]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
